import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

'''
data preprocessing
'''
data_path = "/home/elu/VPP/DLinear_for_price_prediction/data/"
data_path_2024 = data_path + "2024/"
data_path_2025 = data_path + "2025/"

elec_price_df = pd.read_csv(data_path_2024 + "å†…è’™2024ç”µä»·æ•°æ®_24ç‚¹_cleaned.csv", sep="\t")
elec_out_price_df = pd.read_csv(data_path_2024 + "å†…è’™2024ä¸œé€è®¡åˆ’_96ç‚¹_cleaned.csv", sep="\t")
non_martket_elec_gen_df = pd.read_csv(data_path_2024 + "å†…è’™2024éå¸‚åœºåŒ–å‡ºåŠ›_96ç‚¹_cleaned.csv", sep="\t")
ele_load_df = pd.read_csv(data_path_2024 + "å†…è’™2024è´Ÿè·æ•°æ®_96ç‚¹_cleaned.csv", sep="\t")
new_energy_elec_gen_df = pd.read_csv(data_path_2024 + "å†…è’™2024æ–°èƒ½æºå‡ºåŠ›æ•°æ®_96ç‚¹_cleaned.csv", sep="\t")

df_15 = [elec_out_price_df, non_martket_elec_gen_df, ele_load_df, new_energy_elec_gen_df]

for i in range(len(df_15)):
    df = df_15[i]
    df = df.sort_values('datetime')
    df['datetime'] = pd.to_datetime(df['datetime'])
    df.set_index('datetime', inplace=True)
    df = df.resample('H', closed='right', label='right').sum()
    df_15[i] = df
    print(df_15[i].head())

elec_price_df['datetime'] = pd.to_datetime(elec_price_df['datetime'])
elec_price_df.set_index('datetime', inplace=True)

merged_df = pd.concat([elec_price_df] + df_15, axis=1)


target_columns = ['å‘¼åŒ…ä¸œç»Ÿä¸€å‡ºæ¸…ç”µä»·', 'å‘¼åŒ…è¥¿ç»Ÿä¸€å‡ºæ¸…ç”µä»·']

scaler = StandardScaler()
data_scaled = scaler.fit_transform(merged_df.values)
data_array = data_scaled

print(f"\nData shape after normalizationï¼š{data_array.shape}")

'''
build DLinear model
'''
# 2. æ„é€ æ»‘åŠ¨çª—å£æ•°æ® ğŸ”„

def create_sliding_windows(data, input_length, output_length, target_indices):
    """
    æ„é€ æ»‘åŠ¨çª—å£æ•°æ®
    :param data: numpy æ•°ç»„ï¼Œå½¢çŠ¶ (T, num_features)
    :param input_length: è¾“å…¥åºåˆ—é•¿åº¦ï¼ˆä¾‹å¦‚24ä¸ªç‚¹ä»£è¡¨1å¤©ï¼‰
    :param output_length: è¾“å‡ºåºåˆ—é•¿åº¦ï¼ˆé¢„æµ‹ä¸‹ä¸€å¤©çš„24ä¸ªç‚¹ï¼‰
    :param target_indices: ç›®æ ‡ç‰¹å¾åœ¨æ•°æ®ä¸­çš„ç´¢å¼•åˆ—è¡¨
    :return: X, Yï¼Œåˆ†åˆ«ä¸ºè¾“å…¥å’Œç›®æ ‡åºåˆ—
    """
    X, Y = [], []
    total_length = data.shape[0]
    for i in range(total_length - input_length - output_length + 1):
        # å–å‡ºè¾“å…¥åºåˆ—ï¼šè¿‡å» input_length ä¸ªæ—¶é—´ç‚¹çš„æ‰€æœ‰ç‰¹å¾
        x_i = data[i : i + input_length, :]
        # å–å‡ºè¾“å‡ºåºåˆ—ï¼šæ¥ä¸‹æ¥ output_length ä¸ªæ—¶é—´ç‚¹çš„ç›®æ ‡ç‰¹å¾
        y_i = data[i + input_length : i + input_length + output_length, :][:, target_indices]
        X.append(x_i)
        Y.append(y_i)
    return np.array(X), np.array(Y)

# å¯¹äº60åˆ†é’Ÿä¸€ä¸ªç‚¹çš„æƒ…å†µï¼Œä¸€å¤©æœ‰24ä¸ªç‚¹
input_length = 24    # è¾“å…¥åºåˆ—é•¿åº¦ï¼š1å¤©æ•°æ®
output_length = 24   # è¾“å‡ºåºåˆ—é•¿åº¦ï¼šé¢„æµ‹ä¸‹ä¸€å¤©

# è·å–ç›®æ ‡ç‰¹å¾çš„ç´¢å¼•
features = merged_df.columns.tolist()
target_indices = [features.index(col) for col in target_columns]

# æ„é€ æ»‘åŠ¨çª—å£æ•°æ®
X, Y = create_sliding_windows(data_array, input_length, output_length, target_indices)
print(f"\næ„é€ åçš„æ ·æœ¬æ•°é‡ï¼š{X.shape[0]}")
print(f"æ¯ä¸ªè¾“å…¥æ ·æœ¬çš„å½¢çŠ¶ï¼š{X.shape[1:]}")   # (input_length, num_features)
print(f"æ¯ä¸ªç›®æ ‡æ ·æœ¬çš„å½¢çŠ¶ï¼š{Y.shape[1:]}")   # (output_length, len(target_columns))

# 3. æ„é€  PyTorch Dataset å’Œ DataLoader ğŸš€

class TimeSeriesDataset(Dataset):
    def __init__(self, X, Y):
        """
        :param X: numpy æ•°ç»„ï¼Œå½¢çŠ¶ (num_samples, input_length, num_features)
        :param Y: numpy æ•°ç»„ï¼Œå½¢çŠ¶ (num_samples, output_length, num_target_features)
        """
        self.X = torch.tensor(X, dtype=torch.float32)
        self.Y = torch.tensor(Y, dtype=torch.float32)
        
    def __len__(self):
        return self.X.shape[0]
    
    def __getitem__(self, idx):
        return self.X[idx], self.Y[idx]

# åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼ˆä¾‹å¦‚ 80% è®­ç»ƒï¼Œ20% éªŒè¯ï¼‰
split_idx = int(0.8 * X.shape[0])
X_train, Y_train = X[:split_idx], Y[:split_idx]
X_val, Y_val = X[split_idx:], Y[split_idx:]

train_dataset = TimeSeriesDataset(X_train, Y_train)
val_dataset = TimeSeriesDataset(X_val, Y_val)

batch_size = 32
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

# 4. æ„å»º DLinear æ¨¡å‹ ğŸ’¡

class DLinear(nn.Module):
    def __init__(self, input_length, output_length, num_features, target_feature_num):
        """
        :param input_length: è¾“å…¥åºåˆ—çš„æ—¶é—´æ­¥æ•°ï¼ˆ24ä¸ªç‚¹ï¼‰
        :param output_length: è¾“å‡ºåºåˆ—çš„æ—¶é—´æ­¥æ•°ï¼ˆ24ä¸ªç‚¹ï¼‰
        :param num_features: è¾“å…¥ç‰¹å¾æ•°é‡
        :param target_feature_num: ç›®æ ‡ç‰¹å¾æ•°é‡ï¼ˆä¾‹å¦‚2ä¸ªåŒºåŸŸçš„ç”µä»·ï¼‰
        """
        super(DLinear, self).__init__()
        # ä¸ºæ¯ä¸ªè¾“å…¥ç‰¹å¾åˆ›å»ºä¸€ä¸ªç‹¬ç«‹çš„çº¿æ€§å±‚
        self.linear_layers = nn.ModuleList([
            nn.Linear(input_length, output_length) for _ in range(num_features)
        ])
        self.num_features = num_features
        self.target_feature_num = target_feature_num
        
    def forward(self, x):
        """
        :param x: è¾“å…¥å¼ é‡ï¼Œå½¢çŠ¶ (batch_size, input_length, num_features)
        :return: é¢„æµ‹ç»“æœï¼Œå½¢çŠ¶ (batch_size, output_length, target_feature_num)
        """
        out_list = []
        # å¯¹æ¯ä¸ªç‰¹å¾ç‹¬ç«‹è¿›è¡Œé¢„æµ‹
        for i, layer in enumerate(self.linear_layers):
            # å–å‡ºç¬¬ i ä¸ªç‰¹å¾ï¼Œå½¢çŠ¶ï¼š(batch_size, input_length)
            xi = x[:, :, i]
            # çº¿æ€§é¢„æµ‹å¾—åˆ°ï¼š(batch_size, output_length)
            yi = layer(xi)
            out_list.append(yi.unsqueeze(-1))  # å˜ä¸º (batch_size, output_length, 1)
        # æ‹¼æ¥æ‰€æœ‰ç‰¹å¾çš„é¢„æµ‹ç»“æœï¼Œå½¢çŠ¶ï¼š(batch_size, output_length, num_features)
        out = torch.cat(out_list, dim=-1)
        # é€‰æ‹©ç›®æ ‡ç‰¹å¾ï¼ˆè¿™é‡Œå‡è®¾ç›®æ ‡ç‰¹å¾åœ¨æ‰€æœ‰ç‰¹å¾ä¸­ä½äºå‰é¢ï¼‰
        prediction = out[:, :, :self.target_feature_num]
        return prediction

# æ¨¡å‹å‚æ•°
num_features = len(features)           # è¾“å…¥æ‰€æœ‰ç‰¹å¾çš„æ•°é‡
target_feature_num = len(target_columns) # é¢„æµ‹ç›®æ ‡çš„æ•°é‡ï¼ˆ2ä¸ªåŒºåŸŸï¼‰

model = DLinear(input_length=input_length, 
                output_length=output_length, 
                num_features=num_features, 
                target_feature_num=target_feature_num)

print("\nDLinear æ¨¡å‹ç»“æ„ï¼š")
print(model)

# 5. æ¨¡å‹è®­ç»ƒ ğŸ’ª

# å®šä¹‰æŸå¤±å‡½æ•°ï¼ˆå‡æ–¹è¯¯å·®ï¼‰å’Œä¼˜åŒ–å™¨ï¼ˆAdamï¼‰
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

num_epochs = 20  # æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´

train_losses = []
val_losses = []

for epoch in range(num_epochs):
    model.train()
    epoch_train_loss = 0.0
    for batch_X, batch_Y in train_loader:
        optimizer.zero_grad()
        # å‰å‘ä¼ æ’­
        outputs = model(batch_X)
        loss = criterion(outputs, batch_Y)
        # åå‘ä¼ æ’­ä¸ä¼˜åŒ–
        loss.backward()
        optimizer.step()
        epoch_train_loss += loss.item() * batch_X.size(0)
    
    epoch_train_loss /= len(train_dataset)
    train_losses.append(epoch_train_loss)
    
    # éªŒè¯é˜¶æ®µ
    model.eval()
    epoch_val_loss = 0.0
    with torch.no_grad():
        for batch_X, batch_Y in val_loader:
            outputs = model(batch_X)
            loss = criterion(outputs, batch_Y)
            epoch_val_loss += loss.item() * batch_X.size(0)
    epoch_val_loss /= len(val_dataset)
    val_losses.append(epoch_val_loss)
    
    print(f"Epoch {epoch+1}/{num_epochs} - Train Loss: {epoch_train_loss:.6f} - Val Loss: {epoch_val_loss:.6f}")

# 6. å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹ ğŸ“ˆ

plt.figure(figsize=(8, 5))
plt.plot(train_losses, label='Train Loss', marker='o')
plt.plot(val_losses, label='Validation Loss', marker='s')
plt.xlabel('Epoch')
plt.ylabel('MSE Loss')
plt.title('è®­ç»ƒè¿‡ç¨‹æŸå¤±æ›²çº¿')
plt.legend()
plt.grid(True)
plt.show()